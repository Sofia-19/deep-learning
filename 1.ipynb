{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eadf0baf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_data = pd.read_csv(\"public_data//train.csv\")\n",
    "x_test =  pd.read_csv(\"public_data//test_x.csv\")\n",
    "y_test =  pd.read_csv(\"public_data//test_y.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "47a538dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = train_data.drop('t', axis=1).values\n",
    "y_train = train_data['t'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a91f22f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = keras.utils.to_categorical(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9e161e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sofi\\opencv\\lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/75\n",
      "\u001b[1m1238/1238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.5129 - loss: 1.5926 - val_accuracy: 0.7081 - val_loss: 0.8927\n",
      "Epoch 2/75\n",
      "\u001b[1m1238/1238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.7120 - loss: 0.8517 - val_accuracy: 0.7209 - val_loss: 0.7904\n",
      "Epoch 3/75\n",
      "\u001b[1m1238/1238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.7307 - loss: 0.7656 - val_accuracy: 0.7281 - val_loss: 0.7549\n",
      "Epoch 4/75\n",
      "\u001b[1m1238/1238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.7352 - loss: 0.7353 - val_accuracy: 0.7330 - val_loss: 0.7274\n",
      "Epoch 5/75\n",
      "\u001b[1m1238/1238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.7409 - loss: 0.7152 - val_accuracy: 0.7377 - val_loss: 0.7133\n",
      "Epoch 6/75\n",
      "\u001b[1m1238/1238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7455 - loss: 0.6968 - val_accuracy: 0.7404 - val_loss: 0.7012\n",
      "Epoch 7/75\n",
      "\u001b[1m1238/1238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7520 - loss: 0.6725 - val_accuracy: 0.7423 - val_loss: 0.6960\n",
      "Epoch 8/75\n",
      "\u001b[1m1238/1238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7536 - loss: 0.6635 - val_accuracy: 0.7456 - val_loss: 0.6835\n",
      "Epoch 9/75\n",
      "\u001b[1m1238/1238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7571 - loss: 0.6532 - val_accuracy: 0.7480 - val_loss: 0.6782\n",
      "Epoch 10/75\n",
      "\u001b[1m1238/1238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7574 - loss: 0.6512 - val_accuracy: 0.7478 - val_loss: 0.6724\n",
      "Epoch 11/75\n",
      "\u001b[1m1238/1238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.7610 - loss: 0.6339 - val_accuracy: 0.7505 - val_loss: 0.6691\n",
      "Epoch 12/75\n",
      "\u001b[1m1238/1238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.7581 - loss: 0.6327 - val_accuracy: 0.7537 - val_loss: 0.6616\n",
      "Epoch 13/75\n",
      "\u001b[1m1238/1238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7637 - loss: 0.6293 - val_accuracy: 0.7555 - val_loss: 0.6592\n",
      "Epoch 14/75\n",
      "\u001b[1m1238/1238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7695 - loss: 0.6076 - val_accuracy: 0.7541 - val_loss: 0.6549\n",
      "Epoch 15/75\n",
      "\u001b[1m1238/1238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7700 - loss: 0.6061 - val_accuracy: 0.7544 - val_loss: 0.6595\n",
      "Epoch 16/75\n",
      "\u001b[1m1238/1238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.7717 - loss: 0.6028 - val_accuracy: 0.7557 - val_loss: 0.6515\n",
      "Epoch 17/75\n",
      "\u001b[1m1238/1238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7739 - loss: 0.6017 - val_accuracy: 0.7579 - val_loss: 0.6472\n",
      "Epoch 18/75\n",
      "\u001b[1m1238/1238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7744 - loss: 0.5961 - val_accuracy: 0.7571 - val_loss: 0.6483\n",
      "Epoch 19/75\n",
      "\u001b[1m1238/1238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.7777 - loss: 0.5923 - val_accuracy: 0.7562 - val_loss: 0.6480\n",
      "Epoch 20/75\n",
      "\u001b[1m1238/1238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.7726 - loss: 0.5965 - val_accuracy: 0.7595 - val_loss: 0.6421\n",
      "Epoch 21/75\n",
      "\u001b[1m1238/1238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7804 - loss: 0.5833 - val_accuracy: 0.7591 - val_loss: 0.6398\n",
      "Epoch 22/75\n",
      "\u001b[1m1238/1238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7815 - loss: 0.5795 - val_accuracy: 0.7588 - val_loss: 0.6374\n",
      "Epoch 23/75\n",
      "\u001b[1m1238/1238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7806 - loss: 0.5793 - val_accuracy: 0.7600 - val_loss: 0.6367\n",
      "Epoch 24/75\n",
      "\u001b[1m1238/1238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7840 - loss: 0.5726 - val_accuracy: 0.7603 - val_loss: 0.6388\n",
      "Epoch 25/75\n",
      "\u001b[1m1238/1238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7846 - loss: 0.5688 - val_accuracy: 0.7612 - val_loss: 0.6343\n",
      "Epoch 26/75\n",
      "\u001b[1m1238/1238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7840 - loss: 0.5674 - val_accuracy: 0.7631 - val_loss: 0.6328\n",
      "Epoch 27/75\n",
      "\u001b[1m1238/1238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.7818 - loss: 0.5655 - val_accuracy: 0.7604 - val_loss: 0.6372\n",
      "Epoch 28/75\n",
      "\u001b[1m1238/1238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.7878 - loss: 0.5564 - val_accuracy: 0.7625 - val_loss: 0.6316\n",
      "Epoch 29/75\n",
      "\u001b[1m1238/1238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.7869 - loss: 0.5586 - val_accuracy: 0.7633 - val_loss: 0.6289\n",
      "Epoch 30/75\n",
      "\u001b[1m1238/1238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.7865 - loss: 0.5584 - val_accuracy: 0.7650 - val_loss: 0.6294\n",
      "Epoch 31/75\n",
      "\u001b[1m1238/1238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7880 - loss: 0.5507 - val_accuracy: 0.7653 - val_loss: 0.6299\n",
      "Epoch 32/75\n",
      "\u001b[1m1238/1238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.7890 - loss: 0.5471 - val_accuracy: 0.7655 - val_loss: 0.6254\n",
      "Epoch 33/75\n",
      "\u001b[1m1238/1238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7891 - loss: 0.5479 - val_accuracy: 0.7692 - val_loss: 0.6260\n",
      "Epoch 34/75\n",
      "\u001b[1m1238/1238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.7923 - loss: 0.5466 - val_accuracy: 0.7677 - val_loss: 0.6269\n",
      "Epoch 35/75\n",
      "\u001b[1m1238/1238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.7942 - loss: 0.5391 - val_accuracy: 0.7656 - val_loss: 0.6266\n",
      "Epoch 36/75\n",
      "\u001b[1m1238/1238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7971 - loss: 0.5319 - val_accuracy: 0.7694 - val_loss: 0.6228\n",
      "Epoch 37/75\n",
      "\u001b[1m1238/1238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7940 - loss: 0.5389 - val_accuracy: 0.7668 - val_loss: 0.6236\n",
      "Epoch 38/75\n",
      "\u001b[1m1238/1238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7987 - loss: 0.5307 - val_accuracy: 0.7682 - val_loss: 0.6248\n",
      "Epoch 39/75\n",
      "\u001b[1m1238/1238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.7983 - loss: 0.5318 - val_accuracy: 0.7693 - val_loss: 0.6224\n",
      "Epoch 40/75\n",
      "\u001b[1m1238/1238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.7960 - loss: 0.5348 - val_accuracy: 0.7668 - val_loss: 0.6242\n",
      "Epoch 41/75\n",
      "\u001b[1m1238/1238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7997 - loss: 0.5274 - val_accuracy: 0.7665 - val_loss: 0.6265\n",
      "Epoch 42/75\n",
      "\u001b[1m1238/1238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7982 - loss: 0.5259 - val_accuracy: 0.7673 - val_loss: 0.6215\n",
      "Epoch 43/75\n",
      "\u001b[1m1238/1238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.8012 - loss: 0.5159 - val_accuracy: 0.7696 - val_loss: 0.6215\n",
      "Epoch 44/75\n",
      "\u001b[1m1238/1238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.8026 - loss: 0.5200 - val_accuracy: 0.7693 - val_loss: 0.6249\n",
      "Epoch 45/75\n",
      "\u001b[1m1238/1238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8031 - loss: 0.5123 - val_accuracy: 0.7708 - val_loss: 0.6221\n",
      "Epoch 46/75\n",
      "\u001b[1m1238/1238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.8005 - loss: 0.5212 - val_accuracy: 0.7702 - val_loss: 0.6223\n",
      "Epoch 47/75\n",
      "\u001b[1m1238/1238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.8056 - loss: 0.5139 - val_accuracy: 0.7682 - val_loss: 0.6237\n",
      "Epoch 48/75\n",
      "\u001b[1m1238/1238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.8060 - loss: 0.5088 - val_accuracy: 0.7685 - val_loss: 0.6256\n",
      "Epoch 49/75\n",
      "\u001b[1m 885/1238\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8079 - loss: 0.5109"
     ]
    }
   ],
   "source": [
    "model = keras.models.Sequential([\n",
    "            keras.layers.Dense(128, input_dim=x_train.shape[1], activation='relu'),\n",
    "            keras.layers.Dense(64, activation='relu'),\n",
    "            keras.layers.Dense(10, activation='softmax')  \n",
    "        ])\n",
    "    \n",
    "model.compile(optimizer=keras.optimizers.Adam(learning_rate=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train, epochs=75, batch_size=32, validation_split=0.2)\n",
    "        \n",
    "model.save(\"model.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "id": "632593e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model:\n",
    "    def __init__(self):\n",
    "        #self.model = keras.models.load_model(os.path.join('model.keras')) \n",
    "        self.model = keras.models.load_model(os.path.join(os.path.dirname(__file__), 'model.keras'))                           \n",
    "\n",
    "\n",
    "    def predict(self, x_test: np.ndarray) -> np.ndarray:\n",
    "\n",
    "        predictions = self.model.predict(x_test)\n",
    "        return np.argmax(predictions, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "e60cb282",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n"
     ]
    }
   ],
   "source": [
    "model = Model()\n",
    "y_pred=model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "id": "898ce224",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "id": "3280ac13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           2       1.00      1.00      1.00         3\n",
      "           6       1.00      1.00      1.00         1\n",
      "           8       1.00      1.00      1.00         1\n",
      "\n",
      "    accuracy                           1.00         5\n",
      "   macro avg       1.00      1.00      1.00         5\n",
      "weighted avg       1.00      1.00      1.00         5\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af543c0c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
